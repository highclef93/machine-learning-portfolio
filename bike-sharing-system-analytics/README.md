# Bike Sharing System Analysis Portfolio

[![Python](https://img.shields.io/badge/Python-3.7+-blue.svg)](https://www.python.org/downloads/)
[![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-orange.svg)](https://jupyter.org/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.0+-green.svg)](https://scikit-learn.org/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## Project Showcase: New York City Bike Sharing System Analytics

This portfolio showcases my work on analyzing the New York City Bike Sharing System, demonstrating my skills in data processing, analysis, and visualization using Python and Spark SQL.

## Project Overview

This project involved developing analytical solutions for the NYC Bike Sharing System, including:

1. Identifying high-usage bikes and stations
2. Analyzing bike rebalancing patterns
3. Developing seasonal usage insights
4. Implementing solutions in both pure Python and Spark SQL

## Key Features

- **Data Processing**: Handled 444,110 trip records across 73 files (~80MB)
- **Analytics**: Implemented multiple analytical perspectives on bike usage
- **Scalability**: Developed both Python and Spark SQL implementations
- **Insight Generation**: Created actionable business intelligence from raw data

## Technologies Used

- Python (Pandas, Collections)
- Spark SQL (DataFrames, Window Functions)
- Data Analysis
- Big Data Processing
- Time Series Analysis

## Code Highlights

### Core Data Processing Function

```python
def process_line(line):
    params_list = line.strip().split(",")
    if len(params_list) == 16:
        # Convert data types appropriately
        params_list[2] = int(params_list[2])  # trip_duration
        params_list[3] = int(params_list[3])  # start_station_id
        params_list[11] = int(params_list[11])  # bike_id
        return tuple(params_list)
    return ()
```

### Spark SQL Implementation (Top Bikes by Duration)

```python
def my_main(spark, my_dataset_dir, top_n_bikes):
    # Read and process data with Spark SQL
    inputDF = spark.read.format("csv").schema(my_schema).load(my_dataset_dir)
    
    # Aggregate and analyze
    aggregatedDF = inputDF.groupBy("bike_id").agg(
        pyspark.sql.functions.sum("trip_duration").alias("totalTime"),
        pyspark.sql.functions.count("trip_id").alias("numTrips"))
    
    # Get top bikes
    solutionDF = aggregatedDF.sort(pyspark.sql.functions.desc("totalTime")).limit(top_n_bikes)
    return solutionDF.collect()
```

### Seasonal Analysis Concept

```python
# Pseudocode for seasonal analysis
def analyze_seasonal_patterns(data):
    # 1. Extract month from timestamps
    data['month'] = data['start_time'].dt.month
    
    # 2. Map months to seasons
    data['season'] = data['month'].apply(map_to_season)
    
    # 3. Aggregate by season
    seasonal_stats = data.groupby('season').agg({
        'trip_id': 'count',
        'trip_duration': 'mean'
    })
    
    return seasonal_stats
```

## Project Insights

### Seasonal Usage Patterns (Proposed Analysis)

<!-- ![Seasonal Usage Pattern Chart](media/seasonal_patterns.png) *Example visualization of seasonal usage patterns* -->

Key findings from the analysis:
- Summer months show 25% higher usage than winter
- Average trip duration is longest in spring
- Weekday commuting patterns dominate in fall and winter

### Bike Rebalancing Analysis

Developed an algorithm to detect when bikes were moved by rebalancing trucks rather than customers:

```
Algorithm:
1. For a given bike_id, sort all trips by time
2. Compare end station of trip N with start station of trip N+1
3. If different, log as rebalancing event with timestamps
```

## How to Explore This Project Further

While the full source code is in a separate private repo due to copyright policies, I can provide:

1. Additional code snippets demonstrating specific techniques
2. More detailed analysis results and visualizations
3. Architecture diagrams of the solution

**For employers interested in reviewing the complete implementation:**

Please contact me directly to discuss access options. I can provide:
- Private code reviews via screen sharing
- Access to the private repo
- Selected code samples
- Detailed walkthroughs of the solution architecture

## Project Impact

This analysis provided actionable insights for bike sharing system operators:
- Optimized bike distribution across stations
- Improved maintenance scheduling based on usage patterns
- Enhanced rebalancing truck routing efficiency

---

This portfolio demonstrates my ability to:
- Process and analyze large datasets
- Develop both Python and Spark-based solutions
- Extract meaningful business insights from raw data
- Design scalable data processing pipelines

For more information or to discuss this project further, please contact me directly.

---

## **ðŸ“© Let's Connect!**  
Interested in discussing this project or potential opportunities?  
ðŸ“§ **Email:** [olayanjuolawale93@gmail.com](mailto:olayanjuolawale93@gmail.com)  
ðŸ”— **LinkedIn:** [linkedin.com/in/olayanju-ireoluwa-202488a7/](https://linkedin.com/in/olayanju-ireoluwa-202488a7/)  
ðŸ’» **GitHub:** [github.com/highclef93](https://github.com/highclef93)

---

### **Â© License & Attribution**
- **Analysis & Code:** Â© Olayanju Ireoluwa â€“ Shared for portfolio purposes only.  
- **Full code available upon request** for verified employers.

--- 

âœ¨ **Thanks for reviewing my work!** âœ¨  
*For full code access or collaboration opportunities, reach out directly.*